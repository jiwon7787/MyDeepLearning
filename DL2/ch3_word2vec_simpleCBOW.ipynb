{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NNにおける単語処理方法（one-hotベクトル）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MatMul:\n",
    "    def __init__(self, W):\n",
    "        self.params = [W]\n",
    "        self.grads = [np.zeros_like(W)]\n",
    "        self.x = None\n",
    "\n",
    "    def forward(self, x):\n",
    "        W,  = self.params\n",
    "        out = np.dot(x, W)\n",
    "        self.x = x\n",
    "\n",
    "        return out\n",
    "\n",
    "    def backward(self, dout):\n",
    "        W = self.params\n",
    "        dx = np.dot(dout, W.T)\n",
    "        dW = np.dot(self.x.T, dout)\n",
    "        self.grads[0][...] = dW # [0]はdWを格納する行（dbは[1]）\n",
    "\n",
    "        return dx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.67012431 -0.61812647  1.48504869]\n"
     ]
    }
   ],
   "source": [
    "c = np.array([1, 0, 0, 0, 0, 0, 0]) # 入力（コンテキスト）\n",
    "W = np.random.randn(7,3) # 重み（分散表現）\n",
    "layer = MatMul(W)\n",
    "h= layer.forward(c) # 入力に対応する重み要素を抜き出す\n",
    "print(h)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CBOW推論"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 7)\n",
      "(2, 7)\n",
      "(7, 3)\n",
      "[[ 0.64234954  1.4054378  -1.47185823 -1.9459261  -0.41461727 -0.02912885\n",
      "   0.6770045 ]\n",
      " [ 1.10999031  0.39055732 -3.47384457 -2.99413625 -0.44300134 -0.57633968\n",
      "   2.58994825]]\n"
     ]
    }
   ],
   "source": [
    "# サンプル入力データ（前後のコンテキスト）\n",
    "c0 = np.array([[1, 0, 0, 0, 0, 0, 0], [0, 1, 0, 0, 0, 0, 0]])\n",
    "c1 = np.array([[0, 0, 1, 0, 0, 0, 0], [0, 0, 0, 0, 1, 0, 0]])\n",
    "print(c0.shape)\n",
    "print(c1.shape)\n",
    "\n",
    "# 重みの初期化\n",
    "W_in = np.random.randn(7, 3) # 全単語（７）の分散表現（３）を持つ\n",
    "W_out = np.random.randn(3, 7) # 前後コンテキストの分散表現平均（３）からクラス分け（７）スコア出力計算に使う重み\n",
    "print(W_in.shape)\n",
    "\n",
    "# レイヤの生成\n",
    "in_layer0 = MatMul(W_in) # ターゲット前の入力層\n",
    "in_layer1 = MatMul(W_in) # ターゲット後の入力層\n",
    "out_layer = MatMul(W_out) # 出力層\n",
    "\n",
    "# 順伝播\n",
    "h0 = in_layer0.forward(c0) # 入力（コンテキスト）と掛けてターゲット前の単語における分散表現取得\n",
    "h1 = in_layer1.forward(c1) # 入力(コンテキスト)と掛けてターゲット後の単語における分散表現取得\n",
    "h = 0.5 * (h0 + h1) # ターゲット前後の単語における分散表現の平均をとってまとめる（密なベクトル）\n",
    "s = out_layer.forward(h) # スコア出力\n",
    "\n",
    "print(s)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CBOWの学習"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. コープスから入力と正解ラベルを生成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# corpusからcontexts(入力)とtarget(正解ラベル)のリストを生成\n",
    "def create_contexts_target(corpus, window_size=1):\n",
    "    target = corpus[window_size:-window_size] # targetはcorpusの両端からwindow_size分をのぞいたもの\n",
    "    contexts = [] # 下記で取得\n",
    "\n",
    "    # idx番目の前後コンテキストペア（ターゲットの数だけある＝コーパス内のidx番目のtarget）\n",
    "    # 範囲に含まれないlen(corpus)番目からwindow_size分前までも範囲に含まれず、結果コーパス内のtargetのインデックス範囲が求まる\n",
    "    for idx in range(window_size, len(corpus)-window_size):\n",
    "        cs = []\n",
    "        # ターゲット前後のコンテキスト e.g. -1, 0, 1 (0：ターゲット, -1, 1：コンテキスト)\n",
    "        for t in range(-window_size, window_size + 1):\n",
    "            if t == 0: # ターゲットはスキップ\n",
    "                continue\n",
    "            cs.append(corpus[idx + t]) # corpus内ターゲットインデックスの前後コンテキストペアをcsリストに格納\n",
    "        contexts.append(cs) # 現在のターゲット前後コンテキストペアcsをcontextsリストに格納\n",
    "\n",
    "    return np.array(contexts), np.array(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 'you', 1: 'say', 2: 'goodbye', 3: 'and', 4: 'i', 5: 'hello', 6: '.'}\n",
      "corpus:  [0 1 2 3 4 1 5 6]\n",
      "[[0 2]\n",
      " [1 3]\n",
      " [2 4]\n",
      " [3 1]\n",
      " [4 5]\n",
      " [1 6]]\n",
      "[1 2 3 4 1 5]\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append(r\"C:\\Users\\jiwon\\OneDrive\\Desktop\\deep-learning-from-scratch-2-master\")\n",
    "from common.util import preprocess\n",
    "\n",
    "text = 'You say goodbye and I say hello.'\n",
    "corpus, word_to_id, id_to_word = preprocess(text)\n",
    "print(id_to_word)\n",
    "print(\"corpus: \", corpus)\n",
    "\n",
    "contexts, targets = create_contexts_target(corpus, window_size=1)\n",
    "print(contexts)\n",
    "print(targets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. cotexts(入力)とtarget(正解ラベル)をone-hot表現に変換"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_one_hot(corpus, vocab_size):\n",
    "    '''one-hot表現への変換\n",
    "\n",
    "    :param corpus: 単語IDのリスト（1次元もしくは2次元のNumPy配列）\n",
    "    :param vocab_size: 語彙数\n",
    "    :return: one-hot表現（2次元もしくは3次元のNumPy配列）\n",
    "    '''\n",
    "    N = corpus.shape[0] # targetの要素数またはcontextsのコンテキストペア数（データ数）\n",
    "\n",
    "    # target([1,2,3,4,1,5])だった場合\n",
    "    if corpus.ndim == 1:\n",
    "        # targetの要素数×語彙数の0配列作成\n",
    "        one_hot = np.zeros((N, vocab_size), dtype=np.int32)\n",
    "        # idx番目のデータにおけるword_id番目を１にする\n",
    "        for idx, word_id in enumerate(corpus):\n",
    "            one_hot[idx, word_id] = 1 # word_idと0配列の１にしたいインデックスが一致\n",
    "\n",
    "    # contexts([[0,2],[1,3],[2,4],[3,1],[4,5],[1,6]])だった場合\n",
    "    elif corpus.ndim == 2:\n",
    "        # 各コンテキストの要素数（この場合は２）\n",
    "        C = corpus.shape[1]\n",
    "        # コンテキストペア数分における、コンテキスト数×語彙数の0配列作成\n",
    "        one_hot = np.zeros((N, C, vocab_size), dtype=np.int32)\n",
    "        # idx_0番目のコンテキストペアであるwords_idsにおいて(e.g. 0番目のコンテキストペア: [0,2])\n",
    "        for idx_0, word_ids in enumerate(corpus):\n",
    "            # idx_1番目のword_id番目を１にする(e.g. 0番目のword_id: 0, 1番目のword_id: 2)\n",
    "            for idx_1, word_id in enumerate(word_ids):\n",
    "                one_hot[idx_0, idx_1, word_id] = 1 # word_idと0配列の１にしたいインデックスが一致\n",
    "\n",
    "    return one_hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vocab_size:  7\n",
      "(6,)\n",
      "(6, 2)\n",
      "[1 2 3 4 1 5]\n",
      "[[0 2]\n",
      " [1 3]\n",
      " [2 4]\n",
      " [3 1]\n",
      " [4 5]\n",
      " [1 6]]\n",
      "(6, 7)\n",
      "(6, 2, 7)\n",
      "6\n",
      "[[0 1 0 0 0 0 0]\n",
      " [0 0 1 0 0 0 0]\n",
      " [0 0 0 1 0 0 0]\n",
      " [0 0 0 0 1 0 0]\n",
      " [0 1 0 0 0 0 0]\n",
      " [0 0 0 0 0 1 0]]\n",
      "[[[1 0 0 0 0 0 0]\n",
      "  [0 0 1 0 0 0 0]]\n",
      "\n",
      " [[0 1 0 0 0 0 0]\n",
      "  [0 0 0 1 0 0 0]]\n",
      "\n",
      " [[0 0 1 0 0 0 0]\n",
      "  [0 0 0 0 1 0 0]]\n",
      "\n",
      " [[0 0 0 1 0 0 0]\n",
      "  [0 1 0 0 0 0 0]]\n",
      "\n",
      " [[0 0 0 0 1 0 0]\n",
      "  [0 0 0 0 0 1 0]]\n",
      "\n",
      " [[0 1 0 0 0 0 0]\n",
      "  [0 0 0 0 0 0 1]]]\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append(r\"C:\\Users\\jiwon\\OneDrive\\Desktop\\deep-learning-from-scratch-2-master\")\n",
    "from common.util import preprocess\n",
    "\n",
    "text = 'You say goodbye and I say hello.'\n",
    "# 文章をID番号に変換(コーパス)\n",
    "corpus, word_to_id, id_to_word = preprocess(text)\n",
    "\n",
    "vocab_size = len(id_to_word)\n",
    "print(\"vocab_size: \", vocab_size)\n",
    "\n",
    "# コーパスからコンテキスト（入力）とターゲット（正解ラベル）を生成\n",
    "contexts, target = create_contexts_target(corpus, window_size=1)\n",
    "print(target.shape)\n",
    "print(contexts.shape)\n",
    "print(target)\n",
    "print(contexts)\n",
    "\n",
    "# コンテキストとターゲットをhot-oneデータに変換（NNで使えるように）\n",
    "vocab_size = len(id_to_word)\n",
    "contexts_oh = convert_one_hot(contexts, vocab_size)\n",
    "target_oh = convert_one_hot(target, vocab_size)\n",
    "print(target_oh.shape)\n",
    "print(contexts_oh.shape)\n",
    "print(len(contexts_oh))\n",
    "print(target_oh)\n",
    "print(contexts_oh)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "モデル実装"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(r\"C:\\Users\\jiwon\\OneDrive\\Desktop\\deep-learning-from-scratch-2-master\")\n",
    "from common.layers import SoftmaxWithLoss\n",
    "\n",
    "class SimpleCBOW:\n",
    "    #各レイヤのニューロンの数を設定\n",
    "    def __init__(self, vocab_size, hidden_size):\n",
    "        V, H = vocab_size, hidden_size\n",
    "\n",
    "        # 重みの初期化\n",
    "        # 入力(6, 2, 7)と重み(7, 3)の積の結果：(6, 2, 3)\n",
    "        W_in = 0.01 * np.random.randn(V, H).astype('f') # 全語彙の分散表現\n",
    "        W_out = 0.01 * np.random.randn(H, V).astype('f')\n",
    "\n",
    "        # レイヤの生成\n",
    "        self.in_layer0 = MatMul(W_in)\n",
    "        self.in_layer1 = MatMul(W_in)\n",
    "        self.out_layer = MatMul(W_out)\n",
    "        self.loss_layer = SoftmaxWithLoss()\n",
    "\n",
    "        # 全ての重みと勾配をリストにまとめる\n",
    "        layers = [self.in_layer0, self.in_layer1, self.out_layer]\n",
    "        self.params, self.grads = [], []\n",
    "        for layer in layers:\n",
    "            self.params += layer.params\n",
    "            self.grads += layer.grads\n",
    "\n",
    "        # 分散表現(W_in)をメンバ変数に設定（あとで取り出すため）\n",
    "        self.word_vecs = W_in\n",
    "\n",
    "    def forward(self, contexts, target):\n",
    "        h0 = self.in_layer0.forward(contexts[:, 0]) # 入力（コンテキスト）と掛けてターゲット前の単語における分散表現取得\n",
    "        h1 = self.in_layer1.forward(contexts[:, 1]) # 入力(コンテキスト)と掛けてターゲット後の単語における分散表現取得\n",
    "        h = 0.5 * (h0 + h1) # ターゲット前後の単語における分散表現の平均をとってまとめる（密なベクトル）\n",
    "        score = self.out_layer.forward(h) # スコア出力\n",
    "        loss = self.loss_layer.forward(score, target)\n",
    "\n",
    "        return loss\n",
    "\n",
    "    def backward(self, dout=1):\n",
    "        ds = self.loss_layer.backward(dout)\n",
    "        da = self.out_layer.backward(ds)\n",
    "        da *= 0.5\n",
    "        self.in_layer1.backward(da)\n",
    "        self.in_layer0.backward(da)\n",
    "\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "学習コードの実装"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# coding: utf-8\n",
    "import sys\n",
    "\n",
    "sys.path.append(r\"C:\\Users\\jiwon\\OneDrive\\Desktop\\deep-learning-from-scratch-2-master\")\n",
    "import numpy\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "# import numpy as np\n",
    "from common.util import clip_grads\n",
    "\n",
    "\n",
    "class Trainer:\n",
    "    # 一番最初に使用するモデルとパラメータ更新法を設定\n",
    "    def __init__(self, model, optimizer):\n",
    "        self.model = model\n",
    "        self.optimizer = optimizer\n",
    "        self.loss_list = [] # プロット描写用の記録\n",
    "        self.eval_interval = None # 結果を表示する試行間隔（デフォルトでは設定なし：なしのままだと評価の出力されない）\n",
    "        # self.current_epoch = 0\n",
    "        self.current_iter = 0\n",
    "\n",
    "    # 学習の設定（エポック数、バッチサイズ、勾配のノルム最大値（これより小さくする）、結果を表示する試行間隔）\n",
    "    def fit(self, x, t, max_epoch=10, batch_size=32, max_grad=None, eval_interval=None):\n",
    "        data_size = len(x)\n",
    "        max_iters = data_size // batch_size # １エポック\n",
    "        self.eval_interval = eval_interval # 結果を表示する試行間隔\n",
    "        if eval_interval is not None and eval_interval == \"epoch\":\n",
    "            eval_interval = max_iters\n",
    "        model, optimizer = self.model, self.optimizer\n",
    "        # 損失平均の途中経過出力のための記録用\n",
    "        total_loss = 0\n",
    "        loss_count = 0\n",
    "\n",
    "        start_time = time.time()\n",
    "        for epoch in range(max_epoch): # 設定のエポック数まで試行\n",
    "            # ランダムなインデックス要素を含むリストを生成しその並びにデータを置き換える\n",
    "            idx = numpy.random.permutation(numpy.arange(data_size))\n",
    "            x = x[idx]\n",
    "            t = t[idx]\n",
    "\n",
    "            for iters in range(max_iters): # １エポックの間\n",
    "                self.current_iter += 1 # 1エポック過ぎても全体の試行回数を記録する\n",
    "                batch_x = x[iters * batch_size : (iters + 1) * batch_size] # e.g. x[0:30]\n",
    "                batch_t = t[iters * batch_size : (iters + 1) * batch_size] # e.g. t[0:30]\n",
    "\n",
    "\n",
    "                # 損失計算し、勾配を求め、パラメータを更新（学習）\n",
    "                loss = model.forward(batch_x, batch_t)\n",
    "                model.backward()\n",
    "                # パラメータ更新時に共有された重みを1つに集約\n",
    "                params, grads = remove_duplicate(model.params, model.grads)\n",
    "                if max_grad is not None:\n",
    "                    clip_grads(grads, max_grad)\n",
    "                optimizer.update(params, grads)\n",
    "                # 後で損失平均を経過出力するために記録\n",
    "                total_loss += loss\n",
    "                loss_count += 1\n",
    "\n",
    "                # 評価\n",
    "                # eval_intervalが設定されかつのその試行回数に達した時\n",
    "                if (eval_interval is not None) and ((self.current_iter) % eval_interval) == 0:\n",
    "                    avg_loss = total_loss / loss_count\n",
    "                    elapsed_time = time.time() - start_time\n",
    "                    print(\n",
    "                        \"No. %d | epoch %d | iter %d | time %d[s] 0| loss %.2f\"\n",
    "                        % (len(self.loss_list) + 1, epoch + 1, self.current_iter, elapsed_time, avg_loss))\n",
    "                    self.loss_list.append(float(avg_loss)) # プロット描写用に記録\n",
    "                    total_loss, loss_count = 0, 0 # 次の損失平均記録のためリセット\n",
    "\n",
    "            # self.current_epoch += 1\n",
    "\n",
    "    def plot(self, ylim=None):\n",
    "        x = numpy.arange(len(self.loss_list)) # 評価回数を横軸\n",
    "        if ylim is not None:\n",
    "            plt.ylim(*ylim)\n",
    "        plt.plot(x, self.loss_list, label=\"train\") # その時の損失平均を縦軸\n",
    "        plt.xlabel(\"iterations (x\" + str(self.eval_interval) + \")\")\n",
    "        plt.ylabel(\"loss\")\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "class RnnlmTrainer:\n",
    "    def __init__(self, model, optimizer):\n",
    "        self.model = model\n",
    "        self.optimizer = optimizer\n",
    "        self.time_idx = None\n",
    "        self.ppl_list = None\n",
    "        self.eval_interval = None\n",
    "        self.current_epoch = 0\n",
    "\n",
    "    def get_batch(self, x, t, batch_size, time_size):\n",
    "        batch_x = np.empty((batch_size, time_size), dtype=\"i\")\n",
    "        batch_t = np.empty((batch_size, time_size), dtype=\"i\")\n",
    "\n",
    "        data_size = len(x)\n",
    "        jump = data_size // batch_size\n",
    "        offsets = [i * jump for i in range(batch_size)]  # バッチの各サンプルの読み込み開始位置\n",
    "\n",
    "        for time in range(time_size):\n",
    "            for i, offset in enumerate(offsets):\n",
    "                batch_x[i, time] = x[(offset + self.time_idx) % data_size]\n",
    "                batch_t[i, time] = t[(offset + self.time_idx) % data_size]\n",
    "            self.time_idx += 1\n",
    "        return batch_x, batch_t\n",
    "\n",
    "    def fit(self, xs, ts, max_epoch=10, batch_size=20, time_size=35, max_grad=None, eval_interval=20):\n",
    "        data_size = len(xs)\n",
    "        max_iters = data_size // (batch_size * time_size)\n",
    "        self.time_idx = 0\n",
    "        self.ppl_list = []\n",
    "        self.eval_interval = eval_interval\n",
    "        model, optimizer = self.model, self.optimizer\n",
    "        total_loss = 0\n",
    "        loss_count = 0\n",
    "\n",
    "        start_time = time.time()\n",
    "        for epoch in range(max_epoch):\n",
    "            for iters in range(max_iters):\n",
    "                batch_x, batch_t = self.get_batch(xs, ts, batch_size, time_size)\n",
    "\n",
    "                # 勾配を求め、パラメータを更新\n",
    "                loss = model.forward(batch_x, batch_t)\n",
    "                model.backward()\n",
    "                params, grads = remove_duplicate(model.params, model.grads)  # 共有された重みを1つに集約\n",
    "                if max_grad is not None:\n",
    "                    clip_grads(grads, max_grad)\n",
    "                optimizer.update(params, grads)\n",
    "                total_loss += loss\n",
    "                loss_count += 1\n",
    "\n",
    "                # パープレキシティの評価\n",
    "                if (eval_interval is not None) and (iters + 1 % eval_interval) == 0:\n",
    "                    ppl = np.exp(total_loss / loss_count)\n",
    "                    elapsed_time = time.time() - start_time\n",
    "                    print(\n",
    "                        \"| epoch %d |  iter %d / %d | time %d[s] | perplexity %.2f\"\n",
    "                        % (self.current_epoch + 1, iters + 1, max_iters, elapsed_time, ppl)\n",
    "                    )\n",
    "                    self.ppl_list.append(float(ppl))\n",
    "                    total_loss, loss_count = 0, 0\n",
    "\n",
    "            self.current_epoch += 1\n",
    "\n",
    "    def plot(self, ylim=None):\n",
    "        x = numpy.arange(len(self.ppl_list))\n",
    "        if ylim is not None:\n",
    "            plt.ylim(*ylim)\n",
    "        plt.plot(x, self.ppl_list, label=\"train\")\n",
    "        plt.xlabel(\"iterations (x\" + str(self.eval_interval) + \")\")\n",
    "        plt.ylabel(\"perplexity\")\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "def remove_duplicate(params, grads):\n",
    "    \"\"\"\n",
    "    パラメータ配列中の重複する重みをひとつに集約し、\n",
    "    その重みに対応する勾配を加算する\n",
    "    \"\"\"\n",
    "    params, grads = params[:], grads[:]  # copy list\n",
    "\n",
    "    while True:\n",
    "        find_flg = False\n",
    "        L = len(params)\n",
    "\n",
    "        for i in range(0, L - 1):\n",
    "            for j in range(i + 1, L):\n",
    "                # 重みを共有する場合\n",
    "                if params[i] is params[j]:\n",
    "                    grads[i] += grads[j]  # 勾配の加算\n",
    "                    find_flg = True\n",
    "                    params.pop(j)\n",
    "                    grads.pop(j)\n",
    "                # 転置行列として重みを共有する場合（weight tying）\n",
    "                elif (\n",
    "                    params[i].ndim == 2\n",
    "                    and params[j].ndim == 2\n",
    "                    and params[i].T.shape == params[j].shape\n",
    "                    and np.all(params[i].T == params[j])\n",
    "                ):\n",
    "                    grads[i] += grads[j].T\n",
    "                    find_flg = True\n",
    "                    params.pop(j)\n",
    "                    grads.pop(j)\n",
    "\n",
    "                if find_flg:\n",
    "                    break\n",
    "            if find_flg:\n",
    "                break\n",
    "\n",
    "        if not find_flg:\n",
    "            break\n",
    "\n",
    "    return params, grads\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. 1 | epoch 3 | iter 5 | time 0[s] 0| loss 1.95\n",
      "No. 2 | epoch 5 | iter 10 | time 0[s] 0| loss 1.95\n",
      "No. 3 | epoch 8 | iter 15 | time 0[s] 0| loss 1.95\n",
      "No. 4 | epoch 10 | iter 20 | time 0[s] 0| loss 1.95\n",
      "No. 5 | epoch 13 | iter 25 | time 0[s] 0| loss 1.94\n",
      "No. 6 | epoch 15 | iter 30 | time 0[s] 0| loss 1.94\n",
      "No. 7 | epoch 18 | iter 35 | time 0[s] 0| loss 1.94\n",
      "No. 8 | epoch 20 | iter 40 | time 0[s] 0| loss 1.94\n",
      "No. 9 | epoch 23 | iter 45 | time 0[s] 0| loss 1.94\n",
      "No. 10 | epoch 25 | iter 50 | time 0[s] 0| loss 1.94\n",
      "No. 11 | epoch 28 | iter 55 | time 0[s] 0| loss 1.94\n",
      "No. 12 | epoch 30 | iter 60 | time 0[s] 0| loss 1.94\n",
      "No. 13 | epoch 33 | iter 65 | time 0[s] 0| loss 1.93\n",
      "No. 14 | epoch 35 | iter 70 | time 0[s] 0| loss 1.93\n",
      "No. 15 | epoch 38 | iter 75 | time 0[s] 0| loss 1.93\n",
      "No. 16 | epoch 40 | iter 80 | time 0[s] 0| loss 1.92\n",
      "No. 17 | epoch 43 | iter 85 | time 0[s] 0| loss 1.92\n",
      "No. 18 | epoch 45 | iter 90 | time 0[s] 0| loss 1.91\n",
      "No. 19 | epoch 48 | iter 95 | time 0[s] 0| loss 1.91\n",
      "No. 20 | epoch 50 | iter 100 | time 0[s] 0| loss 1.90\n",
      "No. 21 | epoch 53 | iter 105 | time 0[s] 0| loss 1.90\n",
      "No. 22 | epoch 55 | iter 110 | time 0[s] 0| loss 1.89\n",
      "No. 23 | epoch 58 | iter 115 | time 0[s] 0| loss 1.89\n",
      "No. 24 | epoch 60 | iter 120 | time 0[s] 0| loss 1.88\n",
      "No. 25 | epoch 63 | iter 125 | time 0[s] 0| loss 1.87\n",
      "No. 26 | epoch 65 | iter 130 | time 0[s] 0| loss 1.87\n",
      "No. 27 | epoch 68 | iter 135 | time 0[s] 0| loss 1.86\n",
      "No. 28 | epoch 70 | iter 140 | time 0[s] 0| loss 1.85\n",
      "No. 29 | epoch 73 | iter 145 | time 0[s] 0| loss 1.84\n",
      "No. 30 | epoch 75 | iter 150 | time 0[s] 0| loss 1.84\n",
      "No. 31 | epoch 78 | iter 155 | time 0[s] 0| loss 1.82\n",
      "No. 32 | epoch 80 | iter 160 | time 0[s] 0| loss 1.82\n",
      "No. 33 | epoch 83 | iter 165 | time 0[s] 0| loss 1.81\n",
      "No. 34 | epoch 85 | iter 170 | time 0[s] 0| loss 1.79\n",
      "No. 35 | epoch 88 | iter 175 | time 0[s] 0| loss 1.79\n",
      "No. 36 | epoch 90 | iter 180 | time 0[s] 0| loss 1.77\n",
      "No. 37 | epoch 93 | iter 185 | time 0[s] 0| loss 1.77\n",
      "No. 38 | epoch 95 | iter 190 | time 0[s] 0| loss 1.75\n",
      "No. 39 | epoch 98 | iter 195 | time 0[s] 0| loss 1.75\n",
      "No. 40 | epoch 100 | iter 200 | time 0[s] 0| loss 1.72\n",
      "No. 41 | epoch 103 | iter 205 | time 0[s] 0| loss 1.72\n",
      "No. 42 | epoch 105 | iter 210 | time 0[s] 0| loss 1.70\n",
      "No. 43 | epoch 108 | iter 215 | time 0[s] 0| loss 1.70\n",
      "No. 44 | epoch 110 | iter 220 | time 0[s] 0| loss 1.68\n",
      "No. 45 | epoch 113 | iter 225 | time 0[s] 0| loss 1.67\n",
      "No. 46 | epoch 115 | iter 230 | time 0[s] 0| loss 1.66\n",
      "No. 47 | epoch 118 | iter 235 | time 0[s] 0| loss 1.64\n",
      "No. 48 | epoch 120 | iter 240 | time 0[s] 0| loss 1.64\n",
      "No. 49 | epoch 123 | iter 245 | time 0[s] 0| loss 1.63\n",
      "No. 50 | epoch 125 | iter 250 | time 0[s] 0| loss 1.60\n",
      "No. 51 | epoch 128 | iter 255 | time 0[s] 0| loss 1.60\n",
      "No. 52 | epoch 130 | iter 260 | time 0[s] 0| loss 1.58\n",
      "No. 53 | epoch 133 | iter 265 | time 0[s] 0| loss 1.57\n",
      "No. 54 | epoch 135 | iter 270 | time 0[s] 0| loss 1.56\n",
      "No. 55 | epoch 138 | iter 275 | time 0[s] 0| loss 1.54\n",
      "No. 56 | epoch 140 | iter 280 | time 0[s] 0| loss 1.54\n",
      "No. 57 | epoch 143 | iter 285 | time 0[s] 0| loss 1.54\n",
      "No. 58 | epoch 145 | iter 290 | time 0[s] 0| loss 1.49\n",
      "No. 59 | epoch 148 | iter 295 | time 0[s] 0| loss 1.51\n",
      "No. 60 | epoch 150 | iter 300 | time 0[s] 0| loss 1.47\n",
      "No. 61 | epoch 153 | iter 305 | time 0[s] 0| loss 1.48\n",
      "No. 62 | epoch 155 | iter 310 | time 0[s] 0| loss 1.45\n",
      "No. 63 | epoch 158 | iter 315 | time 0[s] 0| loss 1.45\n",
      "No. 64 | epoch 160 | iter 320 | time 0[s] 0| loss 1.43\n",
      "No. 65 | epoch 163 | iter 325 | time 0[s] 0| loss 1.44\n",
      "No. 66 | epoch 165 | iter 330 | time 0[s] 0| loss 1.39\n",
      "No. 67 | epoch 168 | iter 335 | time 0[s] 0| loss 1.40\n",
      "No. 68 | epoch 170 | iter 340 | time 0[s] 0| loss 1.39\n",
      "No. 69 | epoch 173 | iter 345 | time 0[s] 0| loss 1.35\n",
      "No. 70 | epoch 175 | iter 350 | time 0[s] 0| loss 1.39\n",
      "No. 71 | epoch 178 | iter 355 | time 0[s] 0| loss 1.35\n",
      "No. 72 | epoch 180 | iter 360 | time 0[s] 0| loss 1.34\n",
      "No. 73 | epoch 183 | iter 365 | time 0[s] 0| loss 1.35\n",
      "No. 74 | epoch 185 | iter 370 | time 0[s] 0| loss 1.29\n",
      "No. 75 | epoch 188 | iter 375 | time 0[s] 0| loss 1.30\n",
      "No. 76 | epoch 190 | iter 380 | time 0[s] 0| loss 1.29\n",
      "No. 77 | epoch 193 | iter 385 | time 0[s] 0| loss 1.25\n",
      "No. 78 | epoch 195 | iter 390 | time 0[s] 0| loss 1.30\n",
      "No. 79 | epoch 198 | iter 395 | time 0[s] 0| loss 1.26\n",
      "No. 80 | epoch 200 | iter 400 | time 0[s] 0| loss 1.25\n",
      "No. 81 | epoch 203 | iter 405 | time 0[s] 0| loss 1.22\n",
      "No. 82 | epoch 205 | iter 410 | time 0[s] 0| loss 1.25\n",
      "No. 83 | epoch 208 | iter 415 | time 0[s] 0| loss 1.20\n",
      "No. 84 | epoch 210 | iter 420 | time 0[s] 0| loss 1.24\n",
      "No. 85 | epoch 213 | iter 425 | time 0[s] 0| loss 1.20\n",
      "No. 86 | epoch 215 | iter 430 | time 0[s] 0| loss 1.19\n",
      "No. 87 | epoch 218 | iter 435 | time 0[s] 0| loss 1.15\n",
      "No. 88 | epoch 220 | iter 440 | time 0[s] 0| loss 1.20\n",
      "No. 89 | epoch 223 | iter 445 | time 0[s] 0| loss 1.16\n",
      "No. 90 | epoch 225 | iter 450 | time 0[s] 0| loss 1.16\n",
      "No. 91 | epoch 228 | iter 455 | time 0[s] 0| loss 1.15\n",
      "No. 92 | epoch 230 | iter 460 | time 0[s] 0| loss 1.14\n",
      "No. 93 | epoch 233 | iter 465 | time 0[s] 0| loss 1.10\n",
      "No. 94 | epoch 235 | iter 470 | time 0[s] 0| loss 1.15\n",
      "No. 95 | epoch 238 | iter 475 | time 0[s] 0| loss 1.12\n",
      "No. 96 | epoch 240 | iter 480 | time 0[s] 0| loss 1.10\n",
      "No. 97 | epoch 243 | iter 485 | time 0[s] 0| loss 1.10\n",
      "No. 98 | epoch 245 | iter 490 | time 0[s] 0| loss 1.09\n",
      "No. 99 | epoch 248 | iter 495 | time 0[s] 0| loss 1.09\n",
      "No. 100 | epoch 250 | iter 500 | time 0[s] 0| loss 1.07\n",
      "No. 101 | epoch 253 | iter 505 | time 0[s] 0| loss 1.04\n",
      "No. 102 | epoch 255 | iter 510 | time 0[s] 0| loss 1.09\n",
      "No. 103 | epoch 258 | iter 515 | time 0[s] 0| loss 1.06\n",
      "No. 104 | epoch 260 | iter 520 | time 0[s] 0| loss 1.04\n",
      "No. 105 | epoch 263 | iter 525 | time 0[s] 0| loss 1.07\n",
      "No. 106 | epoch 265 | iter 530 | time 0[s] 0| loss 1.00\n",
      "No. 107 | epoch 268 | iter 535 | time 0[s] 0| loss 1.02\n",
      "No. 108 | epoch 270 | iter 540 | time 0[s] 0| loss 1.02\n",
      "No. 109 | epoch 273 | iter 545 | time 0[s] 0| loss 1.02\n",
      "No. 110 | epoch 275 | iter 550 | time 0[s] 0| loss 1.00\n",
      "No. 111 | epoch 278 | iter 555 | time 0[s] 0| loss 0.98\n",
      "No. 112 | epoch 280 | iter 560 | time 0[s] 0| loss 1.02\n",
      "No. 113 | epoch 283 | iter 565 | time 0[s] 0| loss 0.99\n",
      "No. 114 | epoch 285 | iter 570 | time 0[s] 0| loss 0.98\n",
      "No. 115 | epoch 288 | iter 575 | time 0[s] 0| loss 0.97\n",
      "No. 116 | epoch 290 | iter 580 | time 0[s] 0| loss 0.98\n",
      "No. 117 | epoch 293 | iter 585 | time 0[s] 0| loss 0.96\n",
      "No. 118 | epoch 295 | iter 590 | time 0[s] 0| loss 0.97\n",
      "No. 119 | epoch 298 | iter 595 | time 0[s] 0| loss 0.96\n",
      "No. 120 | epoch 300 | iter 600 | time 0[s] 0| loss 0.95\n",
      "No. 121 | epoch 303 | iter 605 | time 0[s] 0| loss 0.94\n",
      "No. 122 | epoch 305 | iter 610 | time 0[s] 0| loss 0.95\n",
      "No. 123 | epoch 308 | iter 615 | time 0[s] 0| loss 0.96\n",
      "No. 124 | epoch 310 | iter 620 | time 0[s] 0| loss 0.91\n",
      "No. 125 | epoch 313 | iter 625 | time 0[s] 0| loss 0.93\n",
      "No. 126 | epoch 315 | iter 630 | time 0[s] 0| loss 0.91\n",
      "No. 127 | epoch 318 | iter 635 | time 0[s] 0| loss 0.92\n",
      "No. 128 | epoch 320 | iter 640 | time 0[s] 0| loss 0.91\n",
      "No. 129 | epoch 323 | iter 645 | time 0[s] 0| loss 0.90\n",
      "No. 130 | epoch 325 | iter 650 | time 0[s] 0| loss 0.91\n",
      "No. 131 | epoch 328 | iter 655 | time 0[s] 0| loss 0.90\n",
      "No. 132 | epoch 330 | iter 660 | time 0[s] 0| loss 0.89\n",
      "No. 133 | epoch 333 | iter 665 | time 0[s] 0| loss 0.90\n",
      "No. 134 | epoch 335 | iter 670 | time 0[s] 0| loss 0.87\n",
      "No. 135 | epoch 338 | iter 675 | time 0[s] 0| loss 0.89\n",
      "No. 136 | epoch 340 | iter 680 | time 0[s] 0| loss 0.86\n",
      "No. 137 | epoch 343 | iter 685 | time 0[s] 0| loss 0.87\n",
      "No. 138 | epoch 345 | iter 690 | time 0[s] 0| loss 0.87\n",
      "No. 139 | epoch 348 | iter 695 | time 0[s] 0| loss 0.87\n",
      "No. 140 | epoch 350 | iter 700 | time 0[s] 0| loss 0.86\n",
      "No. 141 | epoch 353 | iter 705 | time 0[s] 0| loss 0.90\n",
      "No. 142 | epoch 355 | iter 710 | time 0[s] 0| loss 0.81\n",
      "No. 143 | epoch 358 | iter 715 | time 0[s] 0| loss 0.83\n",
      "No. 144 | epoch 360 | iter 720 | time 0[s] 0| loss 0.86\n",
      "No. 145 | epoch 363 | iter 725 | time 0[s] 0| loss 0.86\n",
      "No. 146 | epoch 365 | iter 730 | time 0[s] 0| loss 0.82\n",
      "No. 147 | epoch 368 | iter 735 | time 0[s] 0| loss 0.85\n",
      "No. 148 | epoch 370 | iter 740 | time 0[s] 0| loss 0.82\n",
      "No. 149 | epoch 373 | iter 745 | time 0[s] 0| loss 0.81\n",
      "No. 150 | epoch 375 | iter 750 | time 0[s] 0| loss 0.84\n",
      "No. 151 | epoch 378 | iter 755 | time 0[s] 0| loss 0.79\n",
      "No. 152 | epoch 380 | iter 760 | time 0[s] 0| loss 0.85\n",
      "No. 153 | epoch 383 | iter 765 | time 0[s] 0| loss 0.81\n",
      "No. 154 | epoch 385 | iter 770 | time 0[s] 0| loss 0.81\n",
      "No. 155 | epoch 388 | iter 775 | time 0[s] 0| loss 0.79\n",
      "No. 156 | epoch 390 | iter 780 | time 0[s] 0| loss 0.82\n",
      "No. 157 | epoch 393 | iter 785 | time 0[s] 0| loss 0.82\n",
      "No. 158 | epoch 395 | iter 790 | time 0[s] 0| loss 0.78\n",
      "No. 159 | epoch 398 | iter 795 | time 0[s] 0| loss 0.81\n",
      "No. 160 | epoch 400 | iter 800 | time 0[s] 0| loss 0.77\n",
      "No. 161 | epoch 403 | iter 805 | time 0[s] 0| loss 0.76\n",
      "No. 162 | epoch 405 | iter 810 | time 0[s] 0| loss 0.81\n",
      "No. 163 | epoch 408 | iter 815 | time 0[s] 0| loss 0.80\n",
      "No. 164 | epoch 410 | iter 820 | time 0[s] 0| loss 0.76\n",
      "No. 165 | epoch 413 | iter 825 | time 0[s] 0| loss 0.78\n",
      "No. 166 | epoch 415 | iter 830 | time 0[s] 0| loss 0.77\n",
      "No. 167 | epoch 418 | iter 835 | time 0[s] 0| loss 0.79\n",
      "No. 168 | epoch 420 | iter 840 | time 0[s] 0| loss 0.75\n",
      "No. 169 | epoch 423 | iter 845 | time 0[s] 0| loss 0.74\n",
      "No. 170 | epoch 425 | iter 850 | time 0[s] 0| loss 0.79\n",
      "No. 171 | epoch 428 | iter 855 | time 0[s] 0| loss 0.74\n",
      "No. 172 | epoch 430 | iter 860 | time 0[s] 0| loss 0.78\n",
      "No. 173 | epoch 433 | iter 865 | time 0[s] 0| loss 0.76\n",
      "No. 174 | epoch 435 | iter 870 | time 0[s] 0| loss 0.75\n",
      "No. 175 | epoch 438 | iter 875 | time 0[s] 0| loss 0.78\n",
      "No. 176 | epoch 440 | iter 880 | time 0[s] 0| loss 0.72\n",
      "No. 177 | epoch 443 | iter 885 | time 0[s] 0| loss 0.77\n",
      "No. 178 | epoch 445 | iter 890 | time 0[s] 0| loss 0.72\n",
      "No. 179 | epoch 448 | iter 895 | time 0[s] 0| loss 0.74\n",
      "No. 180 | epoch 450 | iter 900 | time 0[s] 0| loss 0.74\n",
      "No. 181 | epoch 453 | iter 905 | time 0[s] 0| loss 0.71\n",
      "No. 182 | epoch 455 | iter 910 | time 0[s] 0| loss 0.76\n",
      "No. 183 | epoch 458 | iter 915 | time 0[s] 0| loss 0.71\n",
      "No. 184 | epoch 460 | iter 920 | time 0[s] 0| loss 0.76\n",
      "No. 185 | epoch 463 | iter 925 | time 0[s] 0| loss 0.75\n",
      "No. 186 | epoch 465 | iter 930 | time 0[s] 0| loss 0.70\n",
      "No. 187 | epoch 468 | iter 935 | time 0[s] 0| loss 0.70\n",
      "No. 188 | epoch 470 | iter 940 | time 0[s] 0| loss 0.75\n",
      "No. 189 | epoch 473 | iter 945 | time 0[s] 0| loss 0.72\n",
      "No. 190 | epoch 475 | iter 950 | time 0[s] 0| loss 0.72\n",
      "No. 191 | epoch 478 | iter 955 | time 0[s] 0| loss 0.74\n",
      "No. 192 | epoch 480 | iter 960 | time 0[s] 0| loss 0.69\n",
      "No. 193 | epoch 483 | iter 965 | time 0[s] 0| loss 0.74\n",
      "No. 194 | epoch 485 | iter 970 | time 0[s] 0| loss 0.68\n",
      "No. 195 | epoch 488 | iter 975 | time 0[s] 0| loss 0.74\n",
      "No. 196 | epoch 490 | iter 980 | time 0[s] 0| loss 0.68\n",
      "No. 197 | epoch 493 | iter 985 | time 0[s] 0| loss 0.73\n",
      "No. 198 | epoch 495 | iter 990 | time 0[s] 0| loss 0.68\n",
      "No. 199 | epoch 498 | iter 995 | time 0[s] 0| loss 0.68\n",
      "No. 200 | epoch 500 | iter 1000 | time 0[s] 0| loss 0.72\n",
      "No. 201 | epoch 503 | iter 1005 | time 0[s] 0| loss 0.73\n",
      "No. 202 | epoch 505 | iter 1010 | time 0[s] 0| loss 0.67\n",
      "No. 203 | epoch 508 | iter 1015 | time 0[s] 0| loss 0.67\n",
      "No. 204 | epoch 510 | iter 1020 | time 0[s] 0| loss 0.72\n",
      "No. 205 | epoch 513 | iter 1025 | time 0[s] 0| loss 0.72\n",
      "No. 206 | epoch 515 | iter 1030 | time 0[s] 0| loss 0.66\n",
      "No. 207 | epoch 518 | iter 1035 | time 0[s] 0| loss 0.63\n",
      "No. 208 | epoch 520 | iter 1040 | time 0[s] 0| loss 0.74\n",
      "No. 209 | epoch 523 | iter 1045 | time 0[s] 0| loss 0.69\n",
      "No. 210 | epoch 525 | iter 1050 | time 0[s] 0| loss 0.68\n",
      "No. 211 | epoch 528 | iter 1055 | time 0[s] 0| loss 0.63\n",
      "No. 212 | epoch 530 | iter 1060 | time 0[s] 0| loss 0.74\n",
      "No. 213 | epoch 533 | iter 1065 | time 0[s] 0| loss 0.66\n",
      "No. 214 | epoch 535 | iter 1070 | time 0[s] 0| loss 0.70\n",
      "No. 215 | epoch 538 | iter 1075 | time 0[s] 0| loss 0.71\n",
      "No. 216 | epoch 540 | iter 1080 | time 0[s] 0| loss 0.64\n",
      "No. 217 | epoch 543 | iter 1085 | time 0[s] 0| loss 0.64\n",
      "No. 218 | epoch 545 | iter 1090 | time 0[s] 0| loss 0.70\n",
      "No. 219 | epoch 548 | iter 1095 | time 0[s] 0| loss 0.70\n",
      "No. 220 | epoch 550 | iter 1100 | time 0[s] 0| loss 0.64\n",
      "No. 221 | epoch 553 | iter 1105 | time 0[s] 0| loss 0.61\n",
      "No. 222 | epoch 555 | iter 1110 | time 0[s] 0| loss 0.72\n",
      "No. 223 | epoch 558 | iter 1115 | time 0[s] 0| loss 0.70\n",
      "No. 224 | epoch 560 | iter 1120 | time 0[s] 0| loss 0.63\n",
      "No. 225 | epoch 563 | iter 1125 | time 0[s] 0| loss 0.69\n",
      "No. 226 | epoch 565 | iter 1130 | time 0[s] 0| loss 0.63\n",
      "No. 227 | epoch 568 | iter 1135 | time 0[s] 0| loss 0.69\n",
      "No. 228 | epoch 570 | iter 1140 | time 0[s] 0| loss 0.63\n",
      "No. 229 | epoch 573 | iter 1145 | time 0[s] 0| loss 0.69\n",
      "No. 230 | epoch 575 | iter 1150 | time 0[s] 0| loss 0.62\n",
      "No. 231 | epoch 578 | iter 1155 | time 0[s] 0| loss 0.66\n",
      "No. 232 | epoch 580 | iter 1160 | time 0[s] 0| loss 0.65\n",
      "No. 233 | epoch 583 | iter 1165 | time 0[s] 0| loss 0.66\n",
      "No. 234 | epoch 585 | iter 1170 | time 0[s] 0| loss 0.65\n",
      "No. 235 | epoch 588 | iter 1175 | time 0[s] 0| loss 0.67\n",
      "No. 236 | epoch 590 | iter 1180 | time 0[s] 0| loss 0.63\n",
      "No. 237 | epoch 593 | iter 1185 | time 0[s] 0| loss 0.62\n",
      "No. 238 | epoch 595 | iter 1190 | time 0[s] 0| loss 0.68\n",
      "No. 239 | epoch 598 | iter 1195 | time 0[s] 0| loss 0.68\n",
      "No. 240 | epoch 600 | iter 1200 | time 0[s] 0| loss 0.61\n",
      "No. 241 | epoch 603 | iter 1205 | time 0[s] 0| loss 0.64\n",
      "No. 242 | epoch 605 | iter 1210 | time 0[s] 0| loss 0.65\n",
      "No. 243 | epoch 608 | iter 1215 | time 0[s] 0| loss 0.67\n",
      "No. 244 | epoch 610 | iter 1220 | time 0[s] 0| loss 0.61\n",
      "No. 245 | epoch 613 | iter 1225 | time 0[s] 0| loss 0.66\n",
      "No. 246 | epoch 615 | iter 1230 | time 0[s] 0| loss 0.62\n",
      "No. 247 | epoch 618 | iter 1235 | time 0[s] 0| loss 0.60\n",
      "No. 248 | epoch 620 | iter 1240 | time 0[s] 0| loss 0.67\n",
      "No. 249 | epoch 623 | iter 1245 | time 0[s] 0| loss 0.63\n",
      "No. 250 | epoch 625 | iter 1250 | time 0[s] 0| loss 0.64\n",
      "No. 251 | epoch 628 | iter 1255 | time 0[s] 0| loss 0.60\n",
      "No. 252 | epoch 630 | iter 1260 | time 0[s] 0| loss 0.67\n",
      "No. 253 | epoch 633 | iter 1265 | time 0[s] 0| loss 0.69\n",
      "No. 254 | epoch 635 | iter 1270 | time 0[s] 0| loss 0.57\n",
      "No. 255 | epoch 638 | iter 1275 | time 0[s] 0| loss 0.69\n",
      "No. 256 | epoch 640 | iter 1280 | time 0[s] 0| loss 0.57\n",
      "No. 257 | epoch 643 | iter 1285 | time 0[s] 0| loss 0.57\n",
      "No. 258 | epoch 645 | iter 1290 | time 0[s] 0| loss 0.69\n",
      "No. 259 | epoch 648 | iter 1295 | time 0[s] 0| loss 0.59\n",
      "No. 260 | epoch 650 | iter 1300 | time 0[s] 0| loss 0.66\n",
      "No. 261 | epoch 653 | iter 1305 | time 0[s] 0| loss 0.57\n",
      "No. 262 | epoch 655 | iter 1310 | time 0[s] 0| loss 0.68\n",
      "No. 263 | epoch 658 | iter 1315 | time 0[s] 0| loss 0.60\n",
      "No. 264 | epoch 660 | iter 1320 | time 0[s] 0| loss 0.64\n",
      "No. 265 | epoch 663 | iter 1325 | time 0[s] 0| loss 0.64\n",
      "No. 266 | epoch 665 | iter 1330 | time 0[s] 0| loss 0.60\n",
      "No. 267 | epoch 668 | iter 1335 | time 0[s] 0| loss 0.60\n",
      "No. 268 | epoch 670 | iter 1340 | time 0[s] 0| loss 0.64\n",
      "No. 269 | epoch 673 | iter 1345 | time 0[s] 0| loss 0.61\n",
      "No. 270 | epoch 675 | iter 1350 | time 0[s] 0| loss 0.63\n",
      "No. 271 | epoch 678 | iter 1355 | time 0[s] 0| loss 0.65\n",
      "No. 272 | epoch 680 | iter 1360 | time 0[s] 0| loss 0.58\n",
      "No. 273 | epoch 683 | iter 1365 | time 0[s] 0| loss 0.63\n",
      "No. 274 | epoch 685 | iter 1370 | time 0[s] 0| loss 0.60\n",
      "No. 275 | epoch 688 | iter 1375 | time 0[s] 0| loss 0.65\n",
      "No. 276 | epoch 690 | iter 1380 | time 0[s] 0| loss 0.58\n",
      "No. 277 | epoch 693 | iter 1385 | time 0[s] 0| loss 0.65\n",
      "No. 278 | epoch 695 | iter 1390 | time 0[s] 0| loss 0.58\n",
      "No. 279 | epoch 698 | iter 1395 | time 0[s] 0| loss 0.67\n",
      "No. 280 | epoch 700 | iter 1400 | time 0[s] 0| loss 0.55\n",
      "No. 281 | epoch 703 | iter 1405 | time 0[s] 0| loss 0.64\n",
      "No. 282 | epoch 705 | iter 1410 | time 0[s] 0| loss 0.57\n",
      "No. 283 | epoch 708 | iter 1415 | time 0[s] 0| loss 0.62\n",
      "No. 284 | epoch 710 | iter 1420 | time 0[s] 0| loss 0.60\n",
      "No. 285 | epoch 713 | iter 1425 | time 0[s] 0| loss 0.64\n",
      "No. 286 | epoch 715 | iter 1430 | time 0[s] 0| loss 0.57\n",
      "No. 287 | epoch 718 | iter 1435 | time 0[s] 0| loss 0.59\n",
      "No. 288 | epoch 720 | iter 1440 | time 0[s] 0| loss 0.62\n",
      "No. 289 | epoch 723 | iter 1445 | time 0[s] 0| loss 0.64\n",
      "No. 290 | epoch 725 | iter 1450 | time 0[s] 0| loss 0.57\n",
      "No. 291 | epoch 728 | iter 1455 | time 0[s] 0| loss 0.60\n",
      "No. 292 | epoch 730 | iter 1460 | time 0[s] 0| loss 0.61\n",
      "No. 293 | epoch 733 | iter 1465 | time 0[s] 0| loss 0.64\n",
      "No. 294 | epoch 735 | iter 1470 | time 0[s] 0| loss 0.57\n",
      "No. 295 | epoch 738 | iter 1475 | time 0[s] 0| loss 0.58\n",
      "No. 296 | epoch 740 | iter 1480 | time 0[s] 0| loss 0.62\n",
      "No. 297 | epoch 743 | iter 1485 | time 0[s] 0| loss 0.66\n",
      "No. 298 | epoch 745 | iter 1490 | time 0[s] 0| loss 0.54\n",
      "No. 299 | epoch 748 | iter 1495 | time 0[s] 0| loss 0.59\n",
      "No. 300 | epoch 750 | iter 1500 | time 0[s] 0| loss 0.60\n",
      "No. 301 | epoch 753 | iter 1505 | time 0[s] 0| loss 0.59\n",
      "No. 302 | epoch 755 | iter 1510 | time 0[s] 0| loss 0.61\n",
      "No. 303 | epoch 758 | iter 1515 | time 0[s] 0| loss 0.63\n",
      "No. 304 | epoch 760 | iter 1520 | time 0[s] 0| loss 0.56\n",
      "No. 305 | epoch 763 | iter 1525 | time 0[s] 0| loss 0.53\n",
      "No. 306 | epoch 765 | iter 1530 | time 0[s] 0| loss 0.65\n",
      "No. 307 | epoch 768 | iter 1535 | time 0[s] 0| loss 0.58\n",
      "No. 308 | epoch 770 | iter 1540 | time 0[s] 0| loss 0.60\n",
      "No. 309 | epoch 773 | iter 1545 | time 0[s] 0| loss 0.58\n",
      "No. 310 | epoch 775 | iter 1550 | time 0[s] 0| loss 0.60\n",
      "No. 311 | epoch 778 | iter 1555 | time 0[s] 0| loss 0.57\n",
      "No. 312 | epoch 780 | iter 1560 | time 0[s] 0| loss 0.61\n",
      "No. 313 | epoch 783 | iter 1565 | time 0[s] 0| loss 0.62\n",
      "No. 314 | epoch 785 | iter 1570 | time 0[s] 0| loss 0.55\n",
      "No. 315 | epoch 788 | iter 1575 | time 0[s] 0| loss 0.58\n",
      "No. 316 | epoch 790 | iter 1580 | time 0[s] 0| loss 0.59\n",
      "No. 317 | epoch 793 | iter 1585 | time 0[s] 0| loss 0.62\n",
      "No. 318 | epoch 795 | iter 1590 | time 0[s] 0| loss 0.55\n",
      "No. 319 | epoch 798 | iter 1595 | time 0[s] 0| loss 0.62\n",
      "No. 320 | epoch 800 | iter 1600 | time 0[s] 0| loss 0.55\n",
      "No. 321 | epoch 803 | iter 1605 | time 0[s] 0| loss 0.62\n",
      "No. 322 | epoch 805 | iter 1610 | time 0[s] 0| loss 0.55\n",
      "No. 323 | epoch 808 | iter 1615 | time 0[s] 0| loss 0.55\n",
      "No. 324 | epoch 810 | iter 1620 | time 0[s] 0| loss 0.62\n",
      "No. 325 | epoch 813 | iter 1625 | time 0[s] 0| loss 0.60\n",
      "No. 326 | epoch 815 | iter 1630 | time 0[s] 0| loss 0.56\n",
      "No. 327 | epoch 818 | iter 1635 | time 0[s] 0| loss 0.56\n",
      "No. 328 | epoch 820 | iter 1640 | time 0[s] 0| loss 0.60\n",
      "No. 329 | epoch 823 | iter 1645 | time 0[s] 0| loss 0.60\n",
      "No. 330 | epoch 825 | iter 1650 | time 0[s] 0| loss 0.56\n",
      "No. 331 | epoch 828 | iter 1655 | time 0[s] 0| loss 0.61\n",
      "No. 332 | epoch 830 | iter 1660 | time 0[s] 0| loss 0.54\n",
      "No. 333 | epoch 833 | iter 1665 | time 0[s] 0| loss 0.57\n",
      "No. 334 | epoch 835 | iter 1670 | time 0[s] 0| loss 0.58\n",
      "No. 335 | epoch 838 | iter 1675 | time 0[s] 0| loss 0.57\n",
      "No. 336 | epoch 840 | iter 1680 | time 0[s] 0| loss 0.59\n",
      "No. 337 | epoch 843 | iter 1685 | time 0[s] 0| loss 0.59\n",
      "No. 338 | epoch 845 | iter 1690 | time 0[s] 0| loss 0.56\n",
      "No. 339 | epoch 848 | iter 1695 | time 0[s] 0| loss 0.57\n",
      "No. 340 | epoch 850 | iter 1700 | time 0[s] 0| loss 0.58\n",
      "No. 341 | epoch 853 | iter 1705 | time 0[s] 0| loss 0.51\n",
      "No. 342 | epoch 855 | iter 1710 | time 0[s] 0| loss 0.63\n",
      "No. 343 | epoch 858 | iter 1715 | time 0[s] 0| loss 0.54\n",
      "No. 344 | epoch 860 | iter 1720 | time 0[s] 0| loss 0.61\n",
      "No. 345 | epoch 863 | iter 1725 | time 0[s] 0| loss 0.58\n",
      "No. 346 | epoch 865 | iter 1730 | time 0[s] 0| loss 0.56\n",
      "No. 347 | epoch 868 | iter 1735 | time 0[s] 0| loss 0.59\n",
      "No. 348 | epoch 870 | iter 1740 | time 0[s] 0| loss 0.55\n",
      "No. 349 | epoch 873 | iter 1745 | time 0[s] 0| loss 0.58\n",
      "No. 350 | epoch 875 | iter 1750 | time 0[s] 0| loss 0.56\n",
      "No. 351 | epoch 878 | iter 1755 | time 0[s] 0| loss 0.55\n",
      "No. 352 | epoch 880 | iter 1760 | time 0[s] 0| loss 0.59\n",
      "No. 353 | epoch 883 | iter 1765 | time 0[s] 0| loss 0.60\n",
      "No. 354 | epoch 885 | iter 1770 | time 0[s] 0| loss 0.53\n",
      "No. 355 | epoch 888 | iter 1775 | time 0[s] 0| loss 0.63\n",
      "No. 356 | epoch 890 | iter 1780 | time 0[s] 0| loss 0.50\n",
      "No. 357 | epoch 893 | iter 1785 | time 0[s] 0| loss 0.60\n",
      "No. 358 | epoch 895 | iter 1790 | time 0[s] 0| loss 0.53\n",
      "No. 359 | epoch 898 | iter 1795 | time 0[s] 0| loss 0.57\n",
      "No. 360 | epoch 900 | iter 1800 | time 0[s] 0| loss 0.55\n",
      "No. 361 | epoch 903 | iter 1805 | time 0[s] 0| loss 0.60\n",
      "No. 362 | epoch 905 | iter 1810 | time 0[s] 0| loss 0.53\n",
      "No. 363 | epoch 908 | iter 1815 | time 0[s] 0| loss 0.60\n",
      "No. 364 | epoch 910 | iter 1820 | time 0[s] 0| loss 0.53\n",
      "No. 365 | epoch 913 | iter 1825 | time 0[s] 0| loss 0.60\n",
      "No. 366 | epoch 915 | iter 1830 | time 0[s] 0| loss 0.52\n",
      "No. 367 | epoch 918 | iter 1835 | time 0[s] 0| loss 0.59\n",
      "No. 368 | epoch 920 | iter 1840 | time 0[s] 0| loss 0.52\n",
      "No. 369 | epoch 923 | iter 1845 | time 0[s] 0| loss 0.59\n",
      "No. 370 | epoch 925 | iter 1850 | time 0[s] 0| loss 0.52\n",
      "No. 371 | epoch 928 | iter 1855 | time 0[s] 0| loss 0.55\n",
      "No. 372 | epoch 930 | iter 1860 | time 0[s] 0| loss 0.56\n",
      "No. 373 | epoch 933 | iter 1865 | time 0[s] 0| loss 0.52\n",
      "No. 374 | epoch 935 | iter 1870 | time 0[s] 0| loss 0.59\n",
      "No. 375 | epoch 938 | iter 1875 | time 0[s] 0| loss 0.57\n",
      "No. 376 | epoch 940 | iter 1880 | time 0[s] 0| loss 0.54\n",
      "No. 377 | epoch 943 | iter 1885 | time 0[s] 0| loss 0.56\n",
      "No. 378 | epoch 945 | iter 1890 | time 0[s] 0| loss 0.54\n",
      "No. 379 | epoch 948 | iter 1895 | time 0[s] 0| loss 0.57\n",
      "No. 380 | epoch 950 | iter 1900 | time 0[s] 0| loss 0.53\n",
      "No. 381 | epoch 953 | iter 1905 | time 0[s] 0| loss 0.59\n",
      "No. 382 | epoch 955 | iter 1910 | time 0[s] 0| loss 0.52\n",
      "No. 383 | epoch 958 | iter 1915 | time 0[s] 0| loss 0.58\n",
      "No. 384 | epoch 960 | iter 1920 | time 0[s] 0| loss 0.51\n",
      "No. 385 | epoch 963 | iter 1925 | time 0[s] 0| loss 0.56\n",
      "No. 386 | epoch 965 | iter 1930 | time 0[s] 0| loss 0.54\n",
      "No. 387 | epoch 968 | iter 1935 | time 0[s] 0| loss 0.56\n",
      "No. 388 | epoch 970 | iter 1940 | time 0[s] 0| loss 0.54\n",
      "No. 389 | epoch 973 | iter 1945 | time 0[s] 0| loss 0.51\n",
      "No. 390 | epoch 975 | iter 1950 | time 0[s] 0| loss 0.58\n",
      "No. 391 | epoch 978 | iter 1955 | time 0[s] 0| loss 0.58\n",
      "No. 392 | epoch 980 | iter 1960 | time 0[s] 0| loss 0.51\n",
      "No. 393 | epoch 983 | iter 1965 | time 0[s] 0| loss 0.56\n",
      "No. 394 | epoch 985 | iter 1970 | time 0[s] 0| loss 0.53\n",
      "No. 395 | epoch 988 | iter 1975 | time 0[s] 0| loss 0.58\n",
      "No. 396 | epoch 990 | iter 1980 | time 0[s] 0| loss 0.51\n",
      "No. 397 | epoch 993 | iter 1985 | time 0[s] 0| loss 0.55\n",
      "No. 398 | epoch 995 | iter 1990 | time 0[s] 0| loss 0.53\n",
      "No. 399 | epoch 998 | iter 1995 | time 0[s] 0| loss 0.51\n",
      "No. 400 | epoch 1000 | iter 2000 | time 0[s] 0| loss 0.57\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "you [ 1.2721846 -1.0983977 -1.0142385  1.0427588 -1.3667469]\n",
      "say [-0.06346767  1.209302    1.189429   -1.2450265   0.05651998]\n",
      "goodbye [ 0.6203471  -0.8062882  -1.0034034   0.93815655 -0.44453883]\n",
      "and [ 1.6233643  1.0135442  0.9874824 -1.0558016 -1.6445243]\n",
      "i [ 0.63137835 -0.82768166 -1.0054835   0.9404938  -0.44391853]\n",
      "hello [ 1.3002118 -1.0848393 -1.004984   1.0213854 -1.3508834]\n",
      ". [-1.4137777  1.1019249  1.1240877 -1.1203241  1.4073246]\n"
     ]
    }
   ],
   "source": [
    "# coding: utf-8\n",
    "import sys\n",
    "sys.path.append(r\"C:\\Users\\jiwon\\OneDrive\\Desktop\\deep-learning-from-scratch-2-master\")\n",
    "# from common.trainer import Trainer\n",
    "from common.optimizer import Adam\n",
    "# from simple_cbow import SimpleCBOW\n",
    "from common.util import preprocess, create_contexts_target, convert_one_hot\n",
    "\n",
    "\n",
    "window_size = 1\n",
    "hidden_size = 5\n",
    "batch_size = 3\n",
    "max_epoch = 1000\n",
    "\n",
    "text = 'You say goodbye and I say hello.'\n",
    "corpus, word_to_id, id_to_word = preprocess(text)\n",
    "\n",
    "vocab_size = len(word_to_id)\n",
    "contexts, target = create_contexts_target(corpus, window_size)\n",
    "target = convert_one_hot(target, vocab_size)\n",
    "contexts = convert_one_hot(contexts, vocab_size)\n",
    "\n",
    "model = SimpleCBOW(vocab_size, hidden_size)\n",
    "optimizer = Adam()\n",
    "trainer = Trainer(model, optimizer)\n",
    "\n",
    "trainer.fit(contexts, target, max_epoch, batch_size, eval_interval=5)\n",
    "trainer.plot()\n",
    "\n",
    "word_vecs = model.word_vecs\n",
    "for word_id, word in id_to_word.items():\n",
    "    print(word, word_vecs[word_id])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
